"""
ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨ (Manager)

è´Ÿè´£ç®¡ç†æ‰€æœ‰æ•°æ®ç±»åž‹ï¼ˆæ—¥çº¿ã€å¤æƒå› å­ã€åŸºç¡€ä¿¡æ¯ã€æ—¥åŽ†ï¼‰çš„èŽ·å–ã€å­˜å‚¨å’Œæ›´æ–°ã€‚
é‡‡ç”¨åˆ†å±‚æž¶æž„ï¼šProvider â†’ Fetcher â†’ Storage â†’ Manager

æž¶æž„æµç¨‹ï¼š
1. Providerå±‚ï¼šå°è£…APIè°ƒç”¨ï¼ˆTushareProviderï¼‰ï¼Œç¡®ä¿ä¸²è¡Œè°ƒç”¨é¿å…IPè¶…é™
2. Fetcherå±‚ï¼šæ•°æ®èŽ·å–é€»è¾‘ï¼ˆDailyKlineFetcherç­‰ï¼‰ï¼Œè°ƒç”¨ProviderèŽ·å–æ•°æ®
3. Storageå±‚ï¼šæ•°æ®æŒä¹…åŒ–ï¼ˆSQLiteå­˜å‚¨ï¼‰ï¼Œæ‰¹é‡å†™å…¥ä¼˜åŒ–æ€§èƒ½
4. Managerå±‚ï¼šç»Ÿä¸€åè°ƒï¼Œæ™ºèƒ½é€‰æ‹©æ›´æ–°ç­–ç•¥ï¼ˆå…¨é‡/å¢žé‡ï¼‰

æ›´æ–°ç­–ç•¥ï¼š
- å…¨é‡æ›´æ–°ï¼ˆæŒ‰è‚¡ç¥¨ä»£ç ï¼‰ï¼šé¦–æ¬¡çˆ¬å–æ—¶ä½¿ç”¨ï¼ŒéåŽ†æ‰€æœ‰è‚¡ç¥¨èŽ·å–æœ€è¿‘ä¸€å¹´æ•°æ®
- å¢žé‡æ›´æ–°ï¼ˆæŒ‰äº¤æ˜“æ—¥ï¼‰ï¼šå®šæœŸæ›´æ–°æ—¶ä½¿ç”¨ï¼ŒåŸºäºŽæ•°æ®å­˜åœ¨æ€§çŸ©é˜µï¼Œåªæ›´æ–°ç¼ºå¤±æ•°æ®

æ€§èƒ½ä¼˜åŒ–ï¼š
- SQLiteæ‰¹é‡å†™å…¥ï¼šå•æ¬¡äº‹åŠ¡å†™å…¥æ‰€æœ‰æ•°æ®ï¼Œæ€§èƒ½æå‡5-15å€
- çº¿ç¨‹æ± ç®¡ç†ï¼šIOçº¿ç¨‹æ± ï¼ˆ20çº¿ç¨‹ï¼‰å¤„ç†æ–‡ä»¶å†™å…¥ï¼Œä»»åŠ¡çº¿ç¨‹æ± ï¼ˆ1çº¿ç¨‹ï¼‰è°ƒåº¦åŽå°ä»»åŠ¡
- æµæ°´çº¿å¤„ç†ï¼šèŽ·å–å’Œå†™å…¥å¹¶è¡Œè¿›è¡Œï¼Œä¸é˜»å¡žä¸»å¾ªçŽ¯
"""
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional, List
from tqdm import tqdm
from loguru import logger
from functools import cached_property

# Storage (SQLiteç‰ˆæœ¬)
from src.storage.daily_kline_storage_sqlite import DailyKlineStorageSQLite
from src.storage.basic_info_storage_sqlite import BasicInfoStorageSQLite
from src.storage.calendar_storage_sqlite import CalendarStorageSQLite

# Fetchers
from src.fetchers.daily_kline_fetcher import DailyKlineFetcher
from src.fetchers.basic_info_fetcher import BasicInfoFetcher
from src.fetchers.calendar_fetcher import CalendarFetcher

# Matrix Managers


class Manager:
    """
    ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨
    
    èŒè´£ï¼š
    1. ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ•°æ®ç±»åž‹çš„èŽ·å–ã€å­˜å‚¨å’Œæ›´æ–°
    2. ç»´æŠ¤çº¿ç¨‹æ± ä»¥ä¼˜åŒ–èµ„æºä½¿ç”¨
    3. æ™ºèƒ½é€‰æ‹©æ›´æ–°ç­–ç•¥ï¼ˆå…¨é‡æ›´æ–°/å¢žé‡æ›´æ–°ï¼‰
    4. åè°ƒProviderã€Fetcherã€Storageå„å±‚çš„å·¥ä½œ
    
    çº¿ç¨‹æ± è¯´æ˜Žï¼š
    - io_executor: 20ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œç”¨äºŽStorageå±‚çš„å¯†é›†æ–‡ä»¶IOæ“ä½œï¼ˆæ‰¹é‡å†™å…¥ï¼‰
    - task_executor: 1ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œç”¨äºŽManagerå±‚çš„åŽå°ä»»åŠ¡è°ƒåº¦ï¼ˆå¦‚Fetchå®Œæäº¤Writeï¼‰
    
    æ•°æ®æµç¨‹ï¼š
    1. Manager.update_xxx() â†’ è°ƒç”¨å†…éƒ¨æ›´æ–°æ–¹æ³•
    2. _update_stock_data() â†’ æ£€æŸ¥åŽ†å²æ•°æ®ï¼Œé€‰æ‹©æ›´æ–°ç­–ç•¥
    3. _update_all_stocks_full() æˆ– _update_missing_data_incremental() â†’ æ‰§è¡Œæ›´æ–°
    4. Fetcher.fetch_xxx() â†’ è°ƒç”¨ProviderèŽ·å–æ•°æ®
    5. Storage.write_xxx() â†’ å†™å…¥SQLiteæ•°æ®åº“
    """
    
    def __init__(self, provider_name: str = "tushare"):
        """
        åˆå§‹åŒ–Manager
        
        æµç¨‹ï¼š
        1. åˆ›å»ºçº¿ç¨‹æ± ï¼ˆIOçº¿ç¨‹æ± å’Œä»»åŠ¡çº¿ç¨‹æ± ï¼‰
        2. å®žä¾‹åŒ–æ‰€æœ‰Storageç±»ï¼ˆSQLiteç‰ˆæœ¬ï¼‰
        3. å®žä¾‹åŒ–æ‰€æœ‰Fetcherç±»
        4. å®žä¾‹åŒ–Matrix Managerï¼ˆç”¨äºŽå¢žé‡æ›´æ–°ï¼‰
        
        :param provider_name: æ•°æ®æä¾›å•†åç§°ï¼Œé»˜è®¤"tushare"
        """
        # ========== çº¿ç¨‹æ± ç®¡ç† ==========
        # io_executor: ç”¨äºŽ Storage å±‚çš„å¯†é›†æ–‡ä»¶ IO (æ‰¹é‡å†™å…¥)
        #   20ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œå¤„ç†å¹¶å‘å†™å…¥æ“ä½œ
        self.io_executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="IOWorker")
        
        # task_executor: ç”¨äºŽ Manager å±‚çš„åŽå°ä»»åŠ¡è°ƒåº¦ (å¦‚ Fetch å®Œæäº¤ Write)
        #   1ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œç¡®ä¿ä»»åŠ¡æŒ‰é¡ºåºæ‰§è¡Œï¼Œé¿å…èµ„æºç«žäº‰
        self.task_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="TaskWorker")
        
        # ========== å®žä¾‹åŒ– Storageï¼ˆå…¨éƒ¨ä½¿ç”¨SQLiteï¼‰==========
        logger.info("Using SQLite storage for all data types (better performance)")
        self.daily_storage = DailyKlineStorageSQLite()      # æ—¥çº¿è¡Œæƒ…å­˜å‚¨
        self.basic_storage = BasicInfoStorageSQLite()       # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å­˜å‚¨
        self.calendar_storage = CalendarStorageSQLite()      # äº¤æ˜“æ—¥åŽ†å­˜å‚¨
        
        # ========== å®žä¾‹åŒ– Fetchers ==========
        self.daily_fetcher = DailyKlineFetcher(provider_name=provider_name)
        self.basic_fetcher = BasicInfoFetcher(provider_name=provider_name)
        self.calendar_fetcher = CalendarFetcher(provider_name=provider_name)
        

        
        # ========== é…ç½®å‚æ•° ==========
        self.missing_threshold = 1000  # ç¼ºå¤±æ•°æ®é˜ˆå€¼ï¼šå½“æŸæ—¥ç¼ºå¤±è‚¡ç¥¨æ•°è¶…è¿‡æ­¤å€¼æ—¶ï¼Œæ‰¹é‡èŽ·å–è¯¥æ—¥æ‰€æœ‰è‚¡ç¥¨æ•°æ®

    def __del__(self):
        """æ¸…ç†èµ„æºï¼šå…³é—­æ‰€æœ‰çº¿ç¨‹æ± """
        self.io_executor.shutdown(wait=True)
        self.task_executor.shutdown(wait=True)

    # ==================== Public Update Methods ====================

    def update_all(self, mode: str = "code", start_date: str = None, end_date: str = None):
        """
        ä¸€é”®æ›´æ–°æ‰€æœ‰æ•°æ®
        
        æµç¨‹ï¼š
        1. æ›´æ–°åŸºç¡€æ•°æ®ï¼ˆäº¤æ˜“æ—¥åŽ†ã€è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼‰- å¿…é¡»å…ˆæ›´æ–°ï¼Œå…¶ä»–æ•°æ®ä¾èµ–å®ƒä»¬
        2. æ›´æ–°æ ¸å¿ƒæ•°æ®ï¼ˆæ—¥çº¿è¡Œæƒ…ï¼‰- æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ›´æ–°ç­–ç•¥
        
        æ›´æ–°æ¨¡å¼ï¼š
        - codeæ¨¡å¼ï¼šä½¿ç”¨ pro_bar API æŒ‰è‚¡ç¥¨ä»£ç èŽ·å–è¿‡åŽ»ä¸€å¹´çš„æ•°æ®
          * éåŽ†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ¯åªè‚¡ç¥¨è°ƒç”¨ä¸€æ¬¡ pro_bar èŽ·å–å…¨éƒ¨åŽ†å²æ•°æ®
          * é€‚åˆé¦–æ¬¡å…¨é‡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        - dateæ¨¡å¼ï¼šä½¿ç”¨ pro.daily API æŒ‰äº¤æ˜“æ—¥èŽ·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
          * éåŽ†æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥è°ƒç”¨ä¸€æ¬¡ pro.daily èŽ·å–å…¨å¸‚åœºæ•°æ®
          * é€‚åˆå¢žé‡æ›´æ–°ï¼Œè¡¥å……ç‰¹å®šæ—¥æœŸçš„æ•°æ®
        
        :param mode: æ›´æ–°æ¨¡å¼ï¼Œ"code" æˆ– "date"ï¼Œé»˜è®¤ "code"
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
                          - å¦‚æžœä¸ºNoneï¼Œcodeæ¨¡å¼é»˜è®¤ä½¿ç”¨è¿‘ä¸€å¹´æ•°æ®ï¼Œdateæ¨¡å¼ä»Žæœ€æ—©äº¤æ˜“æ—¥å¼€å§‹
                          - codeæ¨¡å¼ï¼šèŽ·å–ä»Žstart_dateåˆ°ä»Šå¤©çš„è¿‘ä¸€å¹´æ•°æ®
                          - dateæ¨¡å¼ï¼šä»Žstart_dateå¼€å§‹æ›´æ–°åˆ°ä»Šå¤©çš„äº¤æ˜“æ—¥æ•°æ®
        """
        if mode not in ["code", "date"]:
            logger.error(f"Invalid mode: {mode}. Must be 'code' or 'date'")
            return
        
        logger.info("=" * 60)
        logger.info("Starting full data update...")
        logger.info(f"Update mode: {mode.upper()}")
        if start_date:
            logger.info(f"Start date: {start_date}")
        else:
            logger.info("Start date: Auto (è¿‘ä¸€å¹´æ•°æ® for code mode)")
        logger.info("=" * 60)
        
        # 1. åŸºç¡€æ•°æ® (Calendar & Basic Info) - å¿…é¡»å…ˆæ›´æ–°ï¼Œå…¶ä»–æ•°æ®ä¾èµ–å®ƒä»¬
        logger.info("Step 1/2: Updating Basic Data (Calendar & Basic Info)...")
        self.update_calendar()
        self.update_basic_info()
        
        # éªŒè¯åŸºç¡€æ•°æ®æ˜¯å¦æ›´æ–°æˆåŠŸ
        stocks = self.all_basic_info
        if stocks is None or stocks.empty:
            logger.error("Failed to get stock codes. Cannot proceed with Daily Kline update.")
            return
        
        logger.success(f"âœ… Basic Info updated. Total stocks: {len(stocks)}")
        logger.success("âœ… Trade Calendar updated.")
        
        # 2. æ ¸å¿ƒæ•°æ® (Daily Kline) - æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ›´æ–°ç­–ç•¥
        logger.info("Step 2/2: Updating Daily Kline Data...")
        self.update_daily_kline(mode=mode, start_date=start_date, end_date=end_date)
        
        logger.info("=" * 60)
        logger.success("ðŸŽ‰ Full data update completed successfully!")
        logger.info("=" * 60)

    def update_daily_kline(self, mode: str = "code", start_date: str = None, end_date: str = None):
        """
        æ›´æ–°æ—¥çº¿è¡Œæƒ…æ•°æ®çš„ä¸»å‡½æ•°
        
        æ”¯æŒä¸¤ç§æ›´æ–°æ¨¡å¼ï¼š
        1. codeæ¨¡å¼ï¼šä½¿ç”¨ pro_bar API æŒ‰è‚¡ç¥¨ä»£ç èŽ·å–è¿‡åŽ»ä¸€å¹´çš„æ•°æ®
           - éåŽ†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ¯åªè‚¡ç¥¨è°ƒç”¨ä¸€æ¬¡ pro_bar èŽ·å–å…¨éƒ¨åŽ†å²æ•°æ®
           - é€‚åˆé¦–æ¬¡å…¨é‡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        2. dateæ¨¡å¼ï¼šä½¿ç”¨ pro.daily API æŒ‰äº¤æ˜“æ—¥èŽ·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
           - éåŽ†æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥è°ƒç”¨ä¸€æ¬¡ pro.daily èŽ·å–å…¨å¸‚åœºæ•°æ®
           - é€‚åˆå¢žé‡æ›´æ–°ï¼Œè¡¥å……ç‰¹å®šæ—¥æœŸçš„æ•°æ®
        
        ä¸¤ç§æ¨¡å¼fetchæ–¹å¼ä¸åŒï¼Œä½†å†™å…¥SQLiteçš„æ–¹å¼ç›¸åŒï¼ˆéƒ½ä½¿ç”¨ write_batchï¼‰
        çˆ¬å–åˆ°æ•°æ®åŽèµ°å¤šçº¿ç¨‹å¹¶å‘æ’å…¥æ•°æ®åº“
        
        æµç¨‹ï¼š
        1. æ ¹æ® mode å‚æ•°é€‰æ‹©æ›´æ–°ç­–ç•¥
        2. codeæ¨¡å¼ï¼šè°ƒç”¨ _update_by_code_mode()
        3. dateæ¨¡å¼ï¼šè°ƒç”¨ _update_by_date_mode()
        4. ä¸¤ç§æ¨¡å¼éƒ½ä½¿ç”¨ io_executor å¤šçº¿ç¨‹å¹¶å‘å†™å…¥
        
        :param mode: æ›´æ–°æ¨¡å¼ï¼Œ"code" æˆ– "date"ï¼Œé»˜è®¤ "code"
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
                          - codeæ¨¡å¼ï¼šèŽ·å–ä»Žstart_dateåˆ°ä»Šå¤©çš„è¿‘ä¸€å¹´æ•°æ®ï¼ˆé»˜è®¤365å¤©ï¼‰
                          - dateæ¨¡å¼ï¼šä»Žstart_dateå¼€å§‹æ›´æ–°åˆ°ä»Šå¤©çš„äº¤æ˜“æ—¥æ•°æ®
        """
        if mode not in ["code", "date"]:
            logger.error(f"Invalid mode: {mode}. Must be 'code' or 'date'")
            return
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        if end_date is None:
            end_date = datetime.now().strftime("%Y%m%d")
        else:
            # å¤„ç† end_date æ ¼å¼ï¼ˆå¯èƒ½æ˜¯ YYYYMMDD æˆ– YYYY-MM-DDï¼‰
            if len(end_date) == 10 and end_date.count("-") == 2:
                try:
                    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                    end_date = end_dt.strftime("%Y%m%d")
                except ValueError:
                    pass
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y%m%d")
        else:
            # å¤„ç† start_date æ ¼å¼ï¼ˆå¯èƒ½æ˜¯ YYYYMMDD æˆ– YYYY-MM-DDï¼‰
            if len(start_date) == 10 and start_date.count("-") == 2:
                try:
                    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
                    start_date = start_dt.strftime("%Y%m%d")
                except ValueError:
                    pass
        
        logger.info(f"Updating Daily Kline Data in {mode} mode from {start_date} to {end_date}")
        
        if mode == "code":
            self._update_by_code_mode(start_date, end_date)
        else:  # mode == "date"
            self._update_by_date_mode(start_date, end_date)


    def update_basic_info(self):
        """
        æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆé€šè¿‡ check_update_needed()ï¼‰
        2. å¦‚æžœéœ€è¦æ›´æ–°ï¼Œè°ƒç”¨ Fetcher èŽ·å–æ•°æ®
        3. å†™å…¥ SQLite æ•°æ®åº“
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¼šæ£€æŸ¥ç¼“å­˜ï¼Œå¦‚æžœä»Šæ—¥å·²æ›´æ–°åˆ™è·³è¿‡
        """
        if self.basic_storage.check_update_needed():
            logger.info("Updating basic info...")
            df = self.basic_fetcher.fetch()
            if df is not None and not df.empty:
                self.basic_storage.write(df)
        else:
            logger.debug("Basic info is up to date.")

    def update_calendar(self, exchange: str = "SSE"):
        """
        æ›´æ–°äº¤æ˜“æ—¥åŽ†
        
        æµç¨‹ï¼š
        1. éåŽ†æ‰€æœ‰äº¤æ˜“æ‰€ï¼ˆSSEã€SZSEï¼‰
        2. æ£€æŸ¥æ¯ä¸ªäº¤æ˜“æ‰€æ˜¯å¦éœ€è¦æ›´æ–°
        3. èŽ·å–æœ€è¿‘ä¸€å¹´çš„äº¤æ˜“æ—¥åŽ†æ•°æ®
        4. å†™å…¥ SQLite æ•°æ®åº“
        
        :param exchange: äº¤æ˜“æ‰€ä»£ç ï¼ˆé»˜è®¤SSEï¼Œä½†å®žé™…ä¼šæ›´æ–°SSEå’ŒSZSEä¸¤ä¸ªï¼‰
        """
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œé€šå¸¸æ›´æ–° SSE å’Œ SZSE
        for ex in ["SSE", "SZSE"]:
            if self.calendar_storage.check_update_needed(ex):
                logger.info(f"Updating calendar for {ex}...")
                now = pd.Timestamp.now()
                end_date = now.strftime("%Y%m%d")
                start_date = (now - timedelta(days=365)).strftime("%Y%m%d")
                
                df = self.calendar_fetcher.fetch(start_date=start_date, end_date=end_date, exchange=ex)
                if df is not None and not df.empty:
                    self.calendar_storage.write(df, exchange=ex)
            else:
                logger.debug(f"Calendar for {ex} is up to date.")

    # ==================== Data Access Methods (Facade) ====================
    
    @cached_property
    def all_basic_info(self) -> pd.DataFrame:
        """
        èŽ·å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆç¼“å­˜å±žæ€§ï¼‰
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        2. å¦‚æžœéœ€è¦ï¼Œè°ƒç”¨ update_basic_info()
        3. ä»Žæ•°æ®åº“åŠ è½½å¹¶è¿”å›ž
        
        :return: åŒ…å«æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯çš„DataFrameï¼Œå¦‚æžœæ•°æ®åº“ä¸ºç©ºåˆ™è¿”å›žç©ºDataFrame
        """
        if self.basic_storage.check_update_needed():
            self.update_basic_info()
        result = self.basic_storage.load()
        return result if result is not None else pd.DataFrame()



    def get_calendar(self, exchange: str = "SSE") -> pd.DataFrame:
        """
        èŽ·å–äº¤æ˜“æ—¥åŽ†ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        2. å¦‚æžœéœ€è¦ï¼Œè°ƒç”¨ update_calendar()
        3. ä»Žæ•°æ®åº“åŠ è½½å¹¶è¿”å›ž
        
        :param exchange: äº¤æ˜“æ‰€ä»£ç ï¼Œé»˜è®¤SSE
        :return: äº¤æ˜“æ—¥åŽ†DataFrame
        """
        if self.calendar_storage.check_update_needed(exchange):
            self.update_calendar(exchange)
        return self.calendar_storage.load(exchange)

    # ==================== Internal Generic Methods ====================



    def _update_by_code_mode(self, start_date: str, end_date: str):
        """
        Codeæ¨¡å¼ï¼šä½¿ç”¨ pro_bar API æŒ‰è‚¡ç¥¨ä»£ç èŽ·å–æ•°æ®
        
        æµç¨‹ï¼š
        1. èŽ·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆä»Ž basic_infoï¼‰
        2. éåŽ†æ¯åªè‚¡ç¥¨ï¼ˆä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼‰
           2.1. è°ƒç”¨ fetcher.fetch_one() ä½¿ç”¨ pro_bar èŽ·å–è¯¥è‚¡ç¥¨è¿‡åŽ»ä¸€å¹´çš„æ•°æ®
           2.2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_batch() æ‰¹é‡å†™å…¥
        3. ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
        
        æ€§èƒ½ç‰¹ç‚¹ï¼š
        - ä½¿ç”¨ task_executor ä¸²è¡Œè°ƒåº¦ä»»åŠ¡ï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼ˆæå‡å†™å…¥æ€§èƒ½ï¼‰
        - é€‚åˆé¦–æ¬¡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        """
        # 1. èŽ·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        basic_info = self.all_basic_info
        if basic_info is None or basic_info.empty:
            logger.error("Failed to get stock codes. Please update basic info first.")
            return
        
        ts_codes = basic_info["ts_code"].tolist()
        logger.info(f"Code mode: Updating Daily Kline for {len(ts_codes)} stocks...")
        
        # 2. éåŽ†è‚¡ç¥¨ä»£ç ï¼Œæ‰¹é‡æ›´æ–°
        pending_futures = []
        for ts_code in tqdm(ts_codes, desc="Fetching by code"):
            # æäº¤åˆ° task_executorï¼Œå¼‚æ­¥èŽ·å–å’Œå†™å…¥
            # task_executor åªæœ‰1ä¸ªçº¿ç¨‹ï¼Œç¡®ä¿ä»»åŠ¡ä¸²è¡Œæ‰§è¡Œï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
            future = self.task_executor.submit(
                self._fetch_and_write_by_code,
                ts_code,
                start_date,
                end_date
            )
            pending_futures.append(future)
        
        # 3. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if pending_futures:
            logger.info("Waiting for all fetch and write tasks to complete...")
            success_count = 0
            for future in tqdm(pending_futures, desc="Writing"):
                try:
                    if future.result():
                        success_count += 1
                except Exception as e:
                    logger.error(f"Task failed: {e}")
            
            logger.info(f"Successfully updated {success_count}/{len(ts_codes)} stocks.")
        
        logger.info("Code mode update completed.")
    
    def _update_by_date_mode(self, start_date: str, end_date: str):
        """
        Dateæ¨¡å¼ï¼šä½¿ç”¨ pro.daily API æŒ‰äº¤æ˜“æ—¥èŽ·å–æ•°æ®
        
        æµç¨‹ï¼š
        1. èŽ·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰äº¤æ˜“æ—¥
        2. éåŽ†æ¯ä¸ªäº¤æ˜“æ—¥ï¼ˆä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼‰
           2.1. è°ƒç”¨ fetcher.fetch_daily_by_date() èŽ·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
           2.2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_batch() æ‰¹é‡å†™å…¥
        3. ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
        
        æ€§èƒ½ç‰¹ç‚¹ï¼š
        - æŒ‰äº¤æ˜“æ—¥æ‰¹é‡èŽ·å–ï¼Œé€‚åˆå¢žé‡æ›´æ–°
        - ä½¿ç”¨ task_executor ä¸²è¡Œè°ƒåº¦ä»»åŠ¡ï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼ˆæå‡å†™å…¥æ€§èƒ½ï¼‰
        - é€‚åˆè¡¥å……ç‰¹å®šæ—¥æœŸçš„ç¼ºå¤±æ•°æ®
        
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        """
        # 1. èŽ·å–æ‰€æœ‰äº¤æ˜“æ—¥
        calendar_df = self.get_calendar()
        if calendar_df is None or calendar_df.empty:
            logger.error("Failed to get trade calendar. Please update calendar first.")
            return
        
        # ç­›é€‰æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥
        # å¤„ç†æ—¥æœŸæ ¼å¼ï¼šcalendar ä¸­çš„æ—¥æœŸå¯èƒ½æ˜¯ YYYY-MM-DD æ ¼å¼
        calendar_df_copy = calendar_df.copy()
        if "cal_date" in calendar_df_copy.columns:
            # ç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿›è¡Œæ¯”è¾ƒ
            calendar_df_copy["cal_date"] = calendar_df_copy["cal_date"].astype(str)
            calendar_df_copy["cal_date"] = calendar_df_copy["cal_date"].apply(
                lambda x: x.replace("-", "") if "-" in x else x
            )
        
        trade_dates = calendar_df_copy[
            (calendar_df_copy['cal_date'] >= start_date) & 
            (calendar_df_copy['cal_date'] <= end_date)
        ]['cal_date'].tolist()
        
        if not trade_dates:
            logger.error(f"No trade dates found in range {start_date}-{end_date}")
            return
        
        trade_dates = sorted(trade_dates)
        logger.info(f"Date mode: Updating Daily Kline for {len(trade_dates)} trade dates...")
        
        # 2. éåŽ†æ¯ä¸ªäº¤æ˜“æ—¥ï¼Œæ‰¹é‡æ›´æ–°
        pending_futures = []
        success_count = 0
        
        for trade_date in tqdm(trade_dates, desc="Fetching by date"):
            try:
                # æäº¤åˆ° task_executorï¼Œå¼‚æ­¥èŽ·å–å’Œå†™å…¥
                # task_executor åªæœ‰1ä¸ªçº¿ç¨‹ï¼Œç¡®ä¿ä»»åŠ¡ä¸²è¡Œæ‰§è¡Œï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
                future = self.task_executor.submit(
                    self._fetch_and_write_by_date,
                    trade_date
                )
                pending_futures.append((trade_date, future))
                success_count += 1
            except Exception as e:
                logger.error(f"Failed to submit task for date {trade_date}: {e}")
        
        # 3. ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
        if pending_futures:
            logger.info("Waiting for all write tasks to complete...")
            write_success = 0
            for trade_date, future in tqdm(pending_futures, desc="Writing"):
                try:
                    if future.result():
                        write_success += 1
                    else:
                        logger.error(f"Write failed for date {trade_date}")
                except Exception as e:
                    logger.error(f"Write task failed for date {trade_date}: {e}")
            
            logger.info(f"Successfully fetched {success_count}/{len(trade_dates)} dates, wrote {write_success}/{len(pending_futures)} dates.")
        
        logger.info("Date mode update completed.")
    
    def _fetch_and_write_by_code(self, ts_code: str, start_date: str, end_date: str) -> bool:
        """
        èŽ·å–å•åªè‚¡ç¥¨æ•°æ®å¹¶å†™å…¥ï¼ˆCodeæ¨¡å¼ï¼‰
        
        æµç¨‹ï¼š
        1. è°ƒç”¨ fetcher.fetch_one() ä½¿ç”¨ pro_bar èŽ·å–è¯¥è‚¡ç¥¨è¿‡åŽ»ä¸€å¹´çš„æ•°æ®
           - ä½¿ç”¨ pro_bar APIï¼Œä¸€æ¬¡èŽ·å–å…¨éƒ¨åŽ†å²æ•°æ®ï¼ˆæ›´å¿«ï¼‰
           - åŒæ—¶èŽ·å–å¤æƒå› å­ï¼ˆfactors="tor"ï¼‰
        2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_batch() æ‰¹é‡å†™å…¥
        3. ç­‰å¾…å†™å…¥å®Œæˆå¹¶è¿”å›žç»“æžœ
        
        æ³¨æ„ï¼š
        - æ­¤æ–¹æ³•åœ¨ task_executor ä¸­æ‰§è¡Œï¼Œå·²ç»æ˜¯ä¸²è¡Œçš„ï¼Œä¸éœ€è¦é¢å¤–å»¶è¿Ÿ
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼Œæå‡æ€§èƒ½
        
        :param ts_code: è‚¡ç¥¨ä»£ç 
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :return: Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        try:
            # Fetch å•åªè‚¡ç¥¨çš„æ•°æ®ï¼ˆä½¿ç”¨ pro_barï¼‰
            df = self.daily_fetcher.fetch_one(ts_code=ts_code, start_date=start_date, end_date=end_date)
            
            if df is None or df.empty:
                logger.debug(f"No data fetched for {ts_code}")
                return False
            
            # æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œæ‰¹é‡å†™å…¥
            future = self.io_executor.submit(self.daily_storage.write_batch, df)
            return future.result() > 0
            
        except Exception as e:
            logger.error(f"Failed to fetch and write {ts_code}: {e}")
            return False
    
    def _fetch_and_write_by_date(self, trade_date: str) -> bool:
        """
        èŽ·å–å•ä¸ªäº¤æ˜“æ—¥æ•°æ®å¹¶å†™å…¥ï¼ˆDateæ¨¡å¼ï¼‰
        
        æµç¨‹ï¼š
        1. è°ƒç”¨ fetcher.fetch_daily_by_date() ä½¿ç”¨ pro.daily èŽ·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_batch() æ‰¹é‡å†™å…¥
        3. ç­‰å¾…å†™å…¥å®Œæˆå¹¶è¿”å›žç»“æžœ
        
        æ³¨æ„ï¼š
        - æ­¤æ–¹æ³•åœ¨ task_executor ä¸­æ‰§è¡Œï¼Œå·²ç»æ˜¯ä¸²è¡Œçš„ï¼Œä¸éœ€è¦é¢å¤–å»¶è¿Ÿ
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼Œæå‡æ€§èƒ½
        
        :param trade_date: äº¤æ˜“æ—¥ï¼Œæ ¼å¼YYYYMMDD
        :return: Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        try:
            # Fetch å•ä¸ªäº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆä½¿ç”¨ pro.dailyï¼‰
            df = self.daily_fetcher.fetch_daily_by_date(trade_date)
            
            if df is None or df.empty:
                logger.debug(f"No data fetched for date {trade_date}")
                return False
            
            # æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œæ‰¹é‡å†™å…¥
            future = self.io_executor.submit(self.daily_storage.write_batch, df)
            return future.result() > 0
            
        except Exception as e:
            logger.error(f"Failed to fetch and write for date {trade_date}: {e}")
            return False

    def _update_all_stocks_full(self, fetcher, storage, data_name: str, start_date: str):
        """
        é¦–æ¬¡å…¨é‡æ›´æ–°ç­–ç•¥ï¼šæŒ‰è‚¡ç¥¨ä»£ç æ‰¹é‡èŽ·å–æœ€è¿‘ä¸€å¹´æ•°æ®
        
        æµç¨‹ï¼š
        1. èŽ·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆä»Ž basic_infoï¼‰
        2. è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆstart_date åˆ° ä»Šå¤©ï¼‰
        3. éåŽ†æ¯åªè‚¡ç¥¨ï¼ˆä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼‰
           3.1. æäº¤åˆ° task_executorï¼Œå¼‚æ­¥æ‰§è¡Œ _fetch_and_write_stock_full()
           3.2. _fetch_and_write_stock_full() ä¼šï¼š
                - è°ƒç”¨ fetcher.fetch_one() èŽ·å–æ•°æ®
                - è°ƒç”¨ storage.write_one() å†™å…¥æ•°æ®ï¼ˆé€šè¿‡ io_executorï¼‰
        4. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        5. æ‰¹é‡åˆ·æ–°ç¼“å­˜ï¼ˆå¦‚æžœæœ‰ï¼‰
        
        æ€§èƒ½ç‰¹ç‚¹ï¼š
        - ä½¿ç”¨ task_executor ä¸²è¡Œè°ƒåº¦ä»»åŠ¡ï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼ˆæå‡å†™å…¥æ€§èƒ½ï¼‰
        - é€‚åˆé¦–æ¬¡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        
        :param fetcher: Fetcherå®žä¾‹
        :param storage: Storageå®žä¾‹
        :param data_name: æ•°æ®åç§°ï¼ˆç”¨äºŽæ—¥å¿—ï¼‰
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        """
        # 1. èŽ·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        basic_info = self.all_basic_info
        if basic_info is None or basic_info.empty:
            logger.error(f"Failed to get stock codes. Please update basic info first.")
            return
        
        ts_codes = basic_info["ts_code"].tolist()
        logger.info(f"Full update: Updating {data_name} for {len(ts_codes)} stocks...")
        
        # 2. è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆæœ€è¿‘ä¸€å¹´ï¼‰
        end_date = datetime.now().strftime("%Y%m%d")
        # å¤„ç† start_date æ ¼å¼ï¼ˆå¯èƒ½æ˜¯ YYYYMMDD æˆ– YYYY-MM-DDï¼‰
        if len(start_date) == 8 and start_date.isdigit():
            start_date_str = start_date
        else:
            try:
                start_dt = datetime.strptime(start_date, "%Y-%m-%d")
                start_date_str = start_dt.strftime("%Y%m%d")
            except ValueError:
                start_date_str = start_date  # å¦‚æžœè§£æžå¤±è´¥ï¼Œç›´æŽ¥ä½¿ç”¨åŽŸå€¼
        
        # 3. éåŽ†è‚¡ç¥¨ä»£ç ï¼Œæ‰¹é‡æ›´æ–°
        pending_futures = []
        for ts_code in tqdm(ts_codes, desc=f"Full update {data_name}"):
            # æäº¤åˆ° task_executorï¼Œå¼‚æ­¥èŽ·å–å’Œå†™å…¥
            # task_executor åªæœ‰1ä¸ªçº¿ç¨‹ï¼Œç¡®ä¿ä»»åŠ¡ä¸²è¡Œæ‰§è¡Œï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
            future = self.task_executor.submit(
                self._fetch_and_write_stock_full,
                fetcher,
                storage,
                ts_code,
                start_date_str,
                end_date
            )
            pending_futures.append(future)
        
        # 4. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if pending_futures:
            logger.info("Waiting for all fetch and write tasks to complete...")
            success_count = 0
            for future in tqdm(pending_futures, desc="Writing"):
                try:
                    if future.result():
                        success_count += 1
                except Exception as e:
                    logger.error(f"Task failed: {e}")
            
            logger.info(f"Successfully updated {success_count}/{len(ts_codes)} stocks.")
        
        # 5. æ‰¹é‡åˆ·æ–°ç¼“å­˜ï¼ˆå¯¹äºŽ adj_factor_storageï¼‰
        if hasattr(storage, 'flush_cache'):
            storage.flush_cache()
            
        logger.info(f"{data_name} full update completed.")



    def _fetch_and_write_stock_full(self, fetcher, storage, ts_code: str, start_date: str, end_date: str) -> bool:
        """
        èŽ·å–å•åªè‚¡ç¥¨å…¨é‡æ•°æ®å¹¶å†™å…¥ï¼ˆç”¨äºŽé¦–æ¬¡å…¨é‡æ›´æ–°ï¼‰
        
        æµç¨‹ï¼š
        1. è°ƒç”¨ fetcher.fetch_one() èŽ·å–æœ€è¿‘ä¸€å¹´æ•°æ®
           - ä½¿ç”¨ pro_bar APIï¼Œä¸€æ¬¡èŽ·å–å…¨éƒ¨åŽ†å²æ•°æ®ï¼ˆæ›´å¿«ï¼‰
           - åŒæ—¶èŽ·å–å¤æƒå› å­ï¼ˆfactors="tor"ï¼‰
        2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_one()
        3. ç­‰å¾…å†™å…¥å®Œæˆå¹¶è¿”å›žç»“æžœ
        
        æ³¨æ„ï¼š
        - æ­¤æ–¹æ³•åœ¨ task_executor ä¸­æ‰§è¡Œï¼Œå·²ç»æ˜¯ä¸²è¡Œçš„ï¼Œä¸éœ€è¦é¢å¤–å»¶è¿Ÿ
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼Œæå‡æ€§èƒ½
        
        :param fetcher: Fetcherå®žä¾‹
        :param storage: Storageå®žä¾‹
        :param ts_code: è‚¡ç¥¨ä»£ç 
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :return: Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        try:
            # Fetch å•åªè‚¡ç¥¨çš„æ•°æ®ï¼ˆæœ€è¿‘ä¸€å¹´ï¼‰
            df = fetcher.fetch_one(ts_code=ts_code, start_date=start_date, end_date=end_date)
            
            if df is None or df.empty:
                logger.debug(f"No data fetched for {ts_code}")
                return False
            
            # ç›´æŽ¥è¦†ç›–å†™å…¥ï¼ˆä½¿ç”¨ io_executorï¼‰
            future = self.io_executor.submit(storage.write_one, ts_code, df)
            return future.result()
            
        except Exception as e:
            logger.error(f"Failed to fetch and write {ts_code}: {e}")
            return False
    
    def _update_all_stocks_by_date(self, fetcher, storage, data_name: str, start_date: str, end_date: str):
        """
        æŒ‰äº¤æ˜“æ—¥å…¨é‡æ›´æ–°ç­–ç•¥ï¼šæŒ‰äº¤æ˜“æ—¥æ‰¹é‡èŽ·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        
        æµç¨‹ï¼š
        1. èŽ·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰äº¤æ˜“æ—¥
        2. éåŽ†æ¯ä¸ªäº¤æ˜“æ—¥ï¼ˆä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼‰
           2.1. è°ƒç”¨ fetcher.fetch_daily_by_date() èŽ·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
           2.2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_daily_by_date()
        3. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        4. æ‰¹é‡åˆ·æ–°ç¼“å­˜ï¼ˆå¦‚æžœæœ‰ï¼‰
        
        æ€§èƒ½ç‰¹ç‚¹ï¼š
        - æŒ‰äº¤æ˜“æ—¥æ‰¹é‡èŽ·å–ï¼Œé€‚åˆå¢žé‡æ›´æ–°
        - ä½¿ç”¨ task_executor ä¸²è¡Œè°ƒåº¦ä»»åŠ¡ï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼ˆæå‡å†™å…¥æ€§èƒ½ï¼‰
        - é€‚åˆè¡¥å……ç‰¹å®šæ—¥æœŸçš„ç¼ºå¤±æ•°æ®
        
        :param fetcher: Fetcherå®žä¾‹
        :param storage: Storageå®žä¾‹
        :param data_name: æ•°æ®åç§°ï¼ˆç”¨äºŽæ—¥å¿—ï¼‰
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        """
        # 1. èŽ·å–æ‰€æœ‰äº¤æ˜“æ—¥
        calendar_df = self.get_calendar()
        if calendar_df is None or calendar_df.empty:
            logger.error(f"Failed to get trade calendar. Please update calendar first.")
            return
        
        # ç­›é€‰æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥
        trade_dates = calendar_df[(calendar_df['cal_date'] >= start_date) & (calendar_df['cal_date'] <= end_date)]['cal_date'].tolist()
        if not trade_dates:
            logger.error(f"No trade dates found in range {start_date}-{end_date}")
            return
        
        trade_dates = sorted(trade_dates)
        logger.info(f"Date-based update: Updating {data_name} for {len(trade_dates)} trade dates...")
        
        # 2. éåŽ†æ¯ä¸ªäº¤æ˜“æ—¥ï¼Œæ‰¹é‡æ›´æ–°
        pending_futures = []
        success_count = 0
        
        for trade_date in tqdm(trade_dates, desc=f"Updating {data_name} by date"):
            try:
                # èŽ·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
                df = fetcher.fetch_daily_by_date(trade_date)
                
                if df is None or df.empty:
                    logger.debug(f"No data fetched for date {trade_date}")
                    continue
                
                # æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œæ‰¹é‡å†™å…¥
                future = self.io_executor.submit(storage.write_daily_by_date, df)
                pending_futures.append((trade_date, future))
                success_count += 1
            except Exception as e:
                logger.error(f"Failed to fetch data for date {trade_date}: {e}")
        
        # 3. ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
        if pending_futures:
            logger.info(f"Waiting for all write tasks to complete...")
            write_success = 0
            for trade_date, future in tqdm(pending_futures, desc="Writing"):
                try:
                    if future.result():
                        write_success += 1
                    else:
                        logger.error(f"Write failed for date {trade_date}")
                except Exception as e:
                    logger.error(f"Write task failed for date {trade_date}: {e}")
            
            logger.info(f"Successfully fetched {success_count}/{len(trade_dates)} dates, wrote {write_success}/{len(pending_futures)} dates.")
        
        # 4. æ‰¹é‡åˆ·æ–°ç¼“å­˜ï¼ˆå¦‚æžœæœ‰ï¼‰
        if hasattr(storage, 'flush_cache'):
            storage.flush_cache()
            
        logger.info(f"{data_name} date-based update completed.")
