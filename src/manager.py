"""
ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨ (Manager)

è´Ÿè´£ç®¡ç†æ‰€æœ‰æ•°æ®ç±»å‹ï¼ˆæ—¥çº¿ã€å¤æƒå› å­ã€åŸºç¡€ä¿¡æ¯ã€æ—¥å†ï¼‰çš„è·å–ã€å­˜å‚¨å’Œæ›´æ–°ã€‚
é‡‡ç”¨åˆ†å±‚æ¶æ„ï¼šProvider â†’ Fetcher â†’ Storage â†’ Manager

æ¶æ„æµç¨‹ï¼š
1. Providerå±‚ï¼šå°è£…APIè°ƒç”¨ï¼ˆTushareProviderï¼‰ï¼Œç¡®ä¿ä¸²è¡Œè°ƒç”¨é¿å…IPè¶…é™
2. Fetcherå±‚ï¼šæ•°æ®è·å–é€»è¾‘ï¼ˆDailyKlineFetcherç­‰ï¼‰ï¼Œè°ƒç”¨Providerè·å–æ•°æ®
3. Storageå±‚ï¼šæ•°æ®æŒä¹…åŒ–ï¼ˆSQLiteå­˜å‚¨ï¼‰ï¼Œæ‰¹é‡å†™å…¥ä¼˜åŒ–æ€§èƒ½
4. Managerå±‚ï¼šç»Ÿä¸€åè°ƒï¼Œæ™ºèƒ½é€‰æ‹©æ›´æ–°ç­–ç•¥ï¼ˆå…¨é‡/å¢é‡ï¼‰

æ›´æ–°ç­–ç•¥ï¼š
- å…¨é‡æ›´æ–°ï¼ˆæŒ‰è‚¡ç¥¨ä»£ç ï¼‰ï¼šé¦–æ¬¡çˆ¬å–æ—¶ä½¿ç”¨ï¼Œéå†æ‰€æœ‰è‚¡ç¥¨è·å–æœ€è¿‘ä¸€å¹´æ•°æ®
- å¢é‡æ›´æ–°ï¼ˆæŒ‰äº¤æ˜“æ—¥ï¼‰ï¼šå®šæœŸæ›´æ–°æ—¶ä½¿ç”¨ï¼ŒåŸºäºæ•°æ®å­˜åœ¨æ€§çŸ©é˜µï¼Œåªæ›´æ–°ç¼ºå¤±æ•°æ®

æ€§èƒ½ä¼˜åŒ–ï¼š
- SQLiteæ‰¹é‡å†™å…¥ï¼šå•æ¬¡äº‹åŠ¡å†™å…¥æ‰€æœ‰æ•°æ®ï¼Œæ€§èƒ½æå‡5-15å€
- çº¿ç¨‹æ± ç®¡ç†ï¼šIOçº¿ç¨‹æ± ï¼ˆ20çº¿ç¨‹ï¼‰å¤„ç†æ–‡ä»¶å†™å…¥ï¼Œä»»åŠ¡çº¿ç¨‹æ± ï¼ˆ1çº¿ç¨‹ï¼‰è°ƒåº¦åå°ä»»åŠ¡
- æµæ°´çº¿å¤„ç†ï¼šè·å–å’Œå†™å…¥å¹¶è¡Œè¿›è¡Œï¼Œä¸é˜»å¡ä¸»å¾ªç¯
"""
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional, List
from tqdm import tqdm
from loguru import logger
from functools import cached_property

# Storage (SQLiteç‰ˆæœ¬)
from src.storage.daily_kline_storage_sqlite import DailyKlineStorageSQLite
from src.storage.basic_info_storage_sqlite import BasicInfoStorageSQLite
from src.storage.calendar_storage_sqlite import CalendarStorageSQLite

# Fetchers
from src.fetchers.daily_kline_fetcher import DailyKlineFetcher
from src.fetchers.basic_info_fetcher import BasicInfoFetcher
from src.fetchers.calendar_fetcher import CalendarFetcher
# utils
from src.utils.date_helper import DateHelper

# Model
from src.models.stock_models import (
    DailyKlineData,
    BasicInfoData,
    TradeCalendarData,
    validate_daily_kline_dataframe,
    validate_basic_info_dataframe
)


class Manager:
    """
    ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨
    
    èŒè´£ï¼š
    1. ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ•°æ®ç±»å‹çš„è·å–ã€å­˜å‚¨å’Œæ›´æ–°
    2. ç»´æŠ¤çº¿ç¨‹æ± ä»¥ä¼˜åŒ–èµ„æºä½¿ç”¨
    3. æ™ºèƒ½é€‰æ‹©æ›´æ–°ç­–ç•¥ï¼ˆå…¨é‡æ›´æ–°/å¢é‡æ›´æ–°ï¼‰
    4. åè°ƒProviderã€Fetcherã€Storageå„å±‚çš„å·¥ä½œ
    
    çº¿ç¨‹æ± è¯´æ˜ï¼š
    - io_executor: 20ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œç”¨äºStorageå±‚çš„å¯†é›†æ–‡ä»¶IOæ“ä½œï¼ˆæ‰¹é‡å†™å…¥ï¼‰
    - task_executor: 1ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œç”¨äºManagerå±‚çš„åå°ä»»åŠ¡è°ƒåº¦ï¼ˆå¦‚Fetchå®Œæäº¤Writeï¼‰
    
    æ•°æ®æµç¨‹ï¼š
    1. Manager.update_xxx() â†’ è°ƒç”¨å†…éƒ¨æ›´æ–°æ–¹æ³•
    2. _update_stock_data() â†’ æ£€æŸ¥å†å²æ•°æ®ï¼Œé€‰æ‹©æ›´æ–°ç­–ç•¥
    3. _update_all_stocks_full() æˆ– _update_missing_data_incremental() â†’ æ‰§è¡Œæ›´æ–°
    4. Fetcher.fetch_xxx() â†’ è°ƒç”¨Providerè·å–æ•°æ®
    5. Storage.write_xxx() â†’ å†™å…¥SQLiteæ•°æ®åº“
    """
    
    def __init__(self, provider_name: str = "tushare"):
        """
        åˆå§‹åŒ–Manager
        
        æµç¨‹ï¼š
        1. åˆ›å»ºçº¿ç¨‹æ± ï¼ˆIOçº¿ç¨‹æ± å’Œä»»åŠ¡çº¿ç¨‹æ± ï¼‰
        2. å®ä¾‹åŒ–æ‰€æœ‰Storageç±»ï¼ˆSQLiteç‰ˆæœ¬ï¼‰
        3. å®ä¾‹åŒ–æ‰€æœ‰Fetcherç±»
        4. å®ä¾‹åŒ–Matrix Managerï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
        
        :param provider_name: æ•°æ®æä¾›å•†åç§°ï¼Œé»˜è®¤"tushare"
        """
        # ========== çº¿ç¨‹æ± ç®¡ç† ==========
        # io_executor: ç”¨äº Storage å±‚çš„å¯†é›†æ–‡ä»¶ IO (æ‰¹é‡å†™å…¥)
        #   20ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œå¤„ç†å¹¶å‘å†™å…¥æ“ä½œ
        self.io_executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="IOWorker")
        
        # task_executor: ç”¨äº Manager å±‚çš„åå°ä»»åŠ¡è°ƒåº¦ (å¦‚ Fetch å®Œæäº¤ Write)
        #   1ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œç¡®ä¿ä»»åŠ¡æŒ‰é¡ºåºæ‰§è¡Œï¼Œé¿å…èµ„æºç«äº‰
        self.task_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="TaskWorker")
        
        # ========== å®ä¾‹åŒ– Storageï¼ˆå…¨éƒ¨ä½¿ç”¨SQLiteï¼‰==========
        logger.info("Using SQLite storage for all data types (better performance)")
        self.daily_storage = DailyKlineStorageSQLite()      # æ—¥çº¿è¡Œæƒ…å­˜å‚¨
        self.basic_storage = BasicInfoStorageSQLite()       # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å­˜å‚¨
        self.calendar_storage = CalendarStorageSQLite()      # äº¤æ˜“æ—¥å†å­˜å‚¨
        
        # ========== å®ä¾‹åŒ– Fetchers ==========
        self.daily_fetcher = DailyKlineFetcher(provider_name=provider_name)
        self.basic_fetcher = BasicInfoFetcher(provider_name=provider_name)
        self.calendar_fetcher = CalendarFetcher(provider_name=provider_name)
        

        
        # ========== é…ç½®å‚æ•° ==========
        self.missing_threshold = 1000  # ç¼ºå¤±æ•°æ®é˜ˆå€¼ï¼šå½“æŸæ—¥ç¼ºå¤±è‚¡ç¥¨æ•°è¶…è¿‡æ­¤å€¼æ—¶ï¼Œæ‰¹é‡è·å–è¯¥æ—¥æ‰€æœ‰è‚¡ç¥¨æ•°æ®

    def __del__(self):
        """æ¸…ç†èµ„æºï¼šå…³é—­æ‰€æœ‰çº¿ç¨‹æ± """
        self.io_executor.shutdown(wait=True)
        self.task_executor.shutdown(wait=True)

    # ==================== Public Update Methods ====================

    def update_all(self, mode: str = "code", start_date: str = None, end_date: str = None):
        """
        ä¸€é”®æ›´æ–°æ‰€æœ‰æ•°æ®
        
        æµç¨‹ï¼š
        1. æ›´æ–°åŸºç¡€æ•°æ®ï¼ˆäº¤æ˜“æ—¥å†ã€è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼‰- å¿…é¡»å…ˆæ›´æ–°ï¼Œå…¶ä»–æ•°æ®ä¾èµ–å®ƒä»¬
        2. æ›´æ–°æ ¸å¿ƒæ•°æ®ï¼ˆæ—¥çº¿è¡Œæƒ…ï¼‰- æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ›´æ–°ç­–ç•¥
        
        æ›´æ–°æ¨¡å¼ï¼š
        - codeæ¨¡å¼ï¼šä½¿ç”¨ pro_bar API æŒ‰è‚¡ç¥¨ä»£ç è·å–è¿‡å»ä¸€å¹´çš„æ•°æ®
          * éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ¯åªè‚¡ç¥¨è°ƒç”¨ä¸€æ¬¡ pro_bar è·å–å…¨éƒ¨å†å²æ•°æ®
          * é€‚åˆé¦–æ¬¡å…¨é‡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        - dateæ¨¡å¼ï¼šä½¿ç”¨ pro.daily API æŒ‰äº¤æ˜“æ—¥è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
          * éå†æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥è°ƒç”¨ä¸€æ¬¡ pro.daily è·å–å…¨å¸‚åœºæ•°æ®
          * é€‚åˆå¢é‡æ›´æ–°ï¼Œè¡¥å……ç‰¹å®šæ—¥æœŸçš„æ•°æ®
        
        :param mode: æ›´æ–°æ¨¡å¼ï¼Œ"code" æˆ– "date"ï¼Œé»˜è®¤ "code"
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
                          - å¦‚æœä¸ºNoneï¼Œcodeæ¨¡å¼é»˜è®¤ä½¿ç”¨è¿‘ä¸€å¹´æ•°æ®ï¼Œdateæ¨¡å¼ä»æœ€æ—©äº¤æ˜“æ—¥å¼€å§‹
                          - codeæ¨¡å¼ï¼šè·å–ä»start_dateåˆ°ä»Šå¤©çš„è¿‘ä¸€å¹´æ•°æ®
                          - dateæ¨¡å¼ï¼šä»start_dateå¼€å§‹æ›´æ–°åˆ°ä»Šå¤©çš„äº¤æ˜“æ—¥æ•°æ®
        """
        if mode not in ["code", "date"]:
            logger.error(f"Invalid mode: {mode}. Must be 'code' or 'date'")
            return
        
        logger.info("=" * 60)
        logger.info("Starting full data update...")
        logger.info(f"Update mode: {mode.upper()}")
        if start_date:
            logger.info(f"Start date: {start_date}")
        else:
            logger.info("Start date: Auto (è¿‘ä¸€å¹´æ•°æ® for code mode)")
        logger.info("=" * 60)
        
        # 1. åŸºç¡€æ•°æ® (Calendar & Basic Info) - å¿…é¡»å…ˆæ›´æ–°ï¼Œå…¶ä»–æ•°æ®ä¾èµ–å®ƒä»¬
        logger.info("Step 1/2: Updating Basic Data (Calendar & Basic Info)...")
        self.update_calendar()
        self.update_basic_info()
        
        # éªŒè¯åŸºç¡€æ•°æ®æ˜¯å¦æ›´æ–°æˆåŠŸ
        stocks = self.all_basic_info
        if stocks is None or stocks.empty:
            logger.error("Failed to get stock codes. Cannot proceed with Daily Kline update.")
            return
        
        logger.success(f"âœ… Basic Info updated. Total stocks: {len(stocks)}")
        logger.success("âœ… Trade Calendar updated.")
        
        # 2. æ ¸å¿ƒæ•°æ® (Daily Kline) - æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æ›´æ–°ç­–ç•¥
        logger.info("Step 2/2: Updating Daily Kline Data...")
        self.update_daily_kline(mode=mode, start_date=start_date, end_date=end_date)
        
        logger.info("=" * 60)
        logger.success("ğŸ‰ Full data update completed successfully!")
        logger.info("=" * 60)

    def update_daily_kline(self, mode: str = "code", start_date: str = None, end_date: str = None):
        """
        æ›´æ–°æ—¥çº¿è¡Œæƒ…æ•°æ®çš„ä¸»å‡½æ•°
        
        æ”¯æŒä¸¤ç§æ›´æ–°æ¨¡å¼ï¼š
        1. codeæ¨¡å¼ï¼šä½¿ç”¨ pro_bar API æŒ‰è‚¡ç¥¨ä»£ç è·å–è¿‡å»ä¸€å¹´çš„æ•°æ®
           - éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ¯åªè‚¡ç¥¨è°ƒç”¨ä¸€æ¬¡ pro_bar è·å–å…¨éƒ¨å†å²æ•°æ®
           - é€‚åˆé¦–æ¬¡å…¨é‡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        2. dateæ¨¡å¼ï¼šä½¿ç”¨ pro.daily API æŒ‰äº¤æ˜“æ—¥è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
           - éå†æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥è°ƒç”¨ä¸€æ¬¡ pro.daily è·å–å…¨å¸‚åœºæ•°æ®
           - é€‚åˆå¢é‡æ›´æ–°ï¼Œè¡¥å……ç‰¹å®šæ—¥æœŸçš„æ•°æ®
        
        ä¸¤ç§æ¨¡å¼fetchæ–¹å¼ä¸åŒï¼Œä½†å†™å…¥SQLiteçš„æ–¹å¼ç›¸åŒï¼ˆéƒ½ä½¿ç”¨ write_batchï¼‰
        çˆ¬å–åˆ°æ•°æ®åèµ°å¤šçº¿ç¨‹å¹¶å‘æ’å…¥æ•°æ®åº“
        
        æµç¨‹ï¼š
        1. æ ¹æ® mode å‚æ•°é€‰æ‹©æ›´æ–°ç­–ç•¥
        2. codeæ¨¡å¼ï¼šè°ƒç”¨ _update_by_code_mode()
        3. dateæ¨¡å¼ï¼šè°ƒç”¨ _update_by_date_mode()
        4. ä¸¤ç§æ¨¡å¼éƒ½ä½¿ç”¨ io_executor å¤šçº¿ç¨‹å¹¶å‘å†™å…¥
        
        :param mode: æ›´æ–°æ¨¡å¼ï¼Œ"code" æˆ– "date"ï¼Œé»˜è®¤ "code"
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
                          - codeæ¨¡å¼ï¼šè·å–ä»start_dateåˆ°ä»Šå¤©çš„è¿‘ä¸€å¹´æ•°æ®ï¼ˆé»˜è®¤365å¤©ï¼‰
                          - dateæ¨¡å¼ï¼šä»start_dateå¼€å§‹æ›´æ–°åˆ°ä»Šå¤©çš„äº¤æ˜“æ—¥æ•°æ®
        """
        if mode not in ["code", "date"]:
            logger.error(f"Invalid mode: {mode}. Must be 'code' or 'date'")
            return
        
        # ä½¿ç”¨ DateHelper ç»Ÿä¸€å¤„ç†æ—¥æœŸæ ¼å¼ï¼ˆManager å†…éƒ¨å…¨éƒ¨ä½¿ç”¨ YYYYMMDDï¼‰
        # æ—¥æœŸåº”è¯¥å·²ç»åœ¨ scripts å±‚è¢«æ ‡å‡†åŒ–ï¼Œè¿™é‡Œåšæœ€åçš„å…œåº•å¤„ç†
        if end_date is None:
            end_date = DateHelper.today()
        
        if start_date is None:
            start_date = DateHelper.days_ago(365)
        
        logger.info(f"Updating Daily Kline Data in {mode} mode from {start_date} to {end_date}")
        
        if mode == "code":
            self._update_by_code_mode(start_date, end_date)
        else:  # mode == "date"
            self._update_by_date_mode(start_date, end_date)

    def update_basic_info(self):
        """
        æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆé€šè¿‡ check_update_needed()ï¼‰
        2. å¦‚æœéœ€è¦æ›´æ–°ï¼Œè°ƒç”¨ Fetcher è·å–æ•°æ®
        3. å†™å…¥ SQLite æ•°æ®åº“
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¼šæ£€æŸ¥ç¼“å­˜ï¼Œå¦‚æœä»Šæ—¥å·²æ›´æ–°åˆ™è·³è¿‡
        """
        if self.basic_storage.check_update_needed():
            logger.info("Updating basic info...")
            df = self.basic_fetcher.fetch()
            validated_df, failed_records = validate_basic_info_dataframe(df)
            if validated_df is not None and not validated_df.empty:
                self.basic_storage.write(validated_df)
            if failed_records:
                logger.warning(f"éªŒè¯è¿‡ç¨‹ä¸­å­˜åœ¨{len(failed_records)}æ¡æ•°æ®éªŒè¯å¤±è´¥")
                for failed_record in failed_records:
                    logger.warning(f"å¤±è´¥æ•°æ®: {failed_record['data']}, é”™è¯¯: {failed_record['error']}")
        else:
            logger.debug("Basic info is up to date.")

    def update_calendar(self, exchange: str = "SSE"):
        """
        æ›´æ–°äº¤æ˜“æ—¥å†
        
        æµç¨‹ï¼š
        1. éå†æ‰€æœ‰äº¤æ˜“æ‰€ï¼ˆSSEã€SZSEï¼‰
        2. æ£€æŸ¥æ¯ä¸ªäº¤æ˜“æ‰€æ˜¯å¦éœ€è¦æ›´æ–°
        3. è·å–æœ€è¿‘ä¸€å¹´çš„äº¤æ˜“æ—¥å†æ•°æ®
        4. å†™å…¥ SQLite æ•°æ®åº“
        
        :param exchange: äº¤æ˜“æ‰€ä»£ç ï¼ˆé»˜è®¤SSEï¼Œä½†å®é™…ä¼šæ›´æ–°SSEå’ŒSZSEä¸¤ä¸ªï¼‰
        """
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œé€šå¸¸æ›´æ–° SSE å’Œ SZSE
        for ex in ["SSE", "SZSE"]:
            if self.calendar_storage.check_update_needed(ex):
                logger.info(f"Updating calendar for {ex}...")
                now = pd.Timestamp.now()
                end_date = now.strftime("%Y%m%d")
                start_date = (now - timedelta(days=365)).strftime("%Y%m%d")
                
                df = self.calendar_fetcher.fetch(start_date=start_date, end_date=end_date, exchange=ex)
                if df is not None and not df.empty:
                    self.calendar_storage.write(df, exchange=ex)
            else:
                logger.debug(f"Calendar for {ex} is up to date.")

    # ==================== Data Access Methods (Facade) ====================
    
    @cached_property
    def all_basic_info(self) -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆç¼“å­˜å±æ€§ï¼‰
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        2. å¦‚æœéœ€è¦ï¼Œè°ƒç”¨ update_basic_info()
        3. ä»æ•°æ®åº“åŠ è½½å¹¶è¿”å›
        
        :return: åŒ…å«æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯çš„DataFrameï¼Œå¦‚æœæ•°æ®åº“ä¸ºç©ºåˆ™è¿”å›ç©ºDataFrame
        """
        if self.basic_storage.check_update_needed():
            self.update_basic_info()
        result = self.basic_storage.load()
        return result if result is not None else pd.DataFrame()

    def get_calendar(self, exchange: str = "SSE") -> pd.DataFrame:
        """
        è·å–äº¤æ˜“æ—¥å†ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        2. å¦‚æœéœ€è¦ï¼Œè°ƒç”¨ update_calendar()
        3. ä»æ•°æ®åº“åŠ è½½å¹¶è¿”å›
        
        :param exchange: äº¤æ˜“æ‰€ä»£ç ï¼Œé»˜è®¤SSE
        :return: äº¤æ˜“æ—¥å†DataFrame
        """
        if self.calendar_storage.check_update_needed(exchange):
            self.update_calendar(exchange)
        return self.calendar_storage.load(exchange)

    # ==================== Internal Generic Methods ====================
    def _fetch_kline_data_by_code(self, ts_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–å•åªè‚¡ç¥¨çš„æ—¥çº¿è¡Œæƒ…æ•°æ®
        
        æµç¨‹ï¼š
        1. è°ƒç”¨ fetcher.fetch_one() ä½¿ç”¨ pro_bar è·å–è¯¥è‚¡ç¥¨çš„æ•°æ®
        2. ä½¿ç”¨ DailyKlineData.validate_dataframe() éªŒè¯æ•°æ®æ ¼å¼
        3. è¿”å›éªŒè¯åçš„ DataFrame
        """
        df = self.daily_fetcher.fetch_one(ts_code=ts_code, start_date=start_date, end_date=end_date)
        validated_df = DailyKlineData.validate_dataframe(df)
        logger.debug(f"Validated {len(validated_df)} rows of kline data for stock {ts_code}")
        return validated_df

    def _fetch_kline_data_by_date(self, trade_date: str) -> pd.DataFrame:
        """
        è·å–æŒ‡å®šäº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ—¥çº¿è¡Œæƒ…æ•°æ®
        
        æµç¨‹ï¼š
        1. è°ƒç”¨ fetcher.fetch_daily_by_date() ä½¿ç”¨ pro.daily è·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        2. ä½¿ç”¨ DailyKlineData.validate_dataframe() éªŒè¯æ•°æ®æ ¼å¼
        3. è¿”å›éªŒè¯åçš„ DataFrame
        """
        df = self.daily_fetcher.fetch_daily_by_date(trade_date=trade_date)
        validated_df = DailyKlineData.validate_dataframe(df)
        logger.debug(f"Validated {len(validated_df)} rows of kline data for trade date {trade_date}")    
        return validated_df

    def _save_kline_data_to_sql(self, df: pd.DataFrame) -> bool:
        """
        å°†æ—¥çº¿è¡Œæƒ…æ•°æ®ä¿å­˜åˆ° SQLite æ•°æ®åº“
        
        æµç¨‹ï¼š
        1. è°ƒç”¨ storage.write_batch() æ‰¹é‡å†™å…¥
        2. è¿”å› True è¡¨ç¤ºæˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥
        """
        logger.debug(f"Saving {len(df)} rows of kline data to SQLite...")
        return self.daily_storage.write(df)

    def _update_by_code_mode(self, start_date: str, end_date: str):
        """
        Codeæ¨¡å¼ï¼šä½¿ç”¨ pro_bar API æŒ‰è‚¡ç¥¨ä»£ç è·å–æ•°æ®
        
        æµç¨‹ï¼š
        1. è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆä» basic_infoï¼‰
        2. éå†æ¯åªè‚¡ç¥¨ï¼ˆä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼‰
           2.1. è°ƒç”¨ fetcher.fetch_one() ä½¿ç”¨ pro_bar è·å–è¯¥è‚¡ç¥¨è¿‡å»ä¸€å¹´çš„æ•°æ®
           2.2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_batch() æ‰¹é‡å†™å…¥
        3. ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
        
        æ€§èƒ½ç‰¹ç‚¹ï¼š
        - ä½¿ç”¨ task_executor ä¸²è¡Œè°ƒåº¦ä»»åŠ¡ï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼ˆæå‡å†™å…¥æ€§èƒ½ï¼‰
        - é€‚åˆé¦–æ¬¡çˆ¬å–ï¼Œæ•°æ®å®Œæ•´
        
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        """
        # 1. è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        basic_info = self.all_basic_info
        if basic_info is None or basic_info.empty:
            logger.error("Failed to get stock codes. Please update basic info first.")
            return
        
        ts_codes = basic_info["ts_code"].tolist()
        logger.info(f"Code mode: Updating Daily Kline for {len(ts_codes)} stocks...")
        
        # 2. éå†è‚¡ç¥¨ä»£ç ï¼Œæ‰¹é‡æ›´æ–°
        pending_futures = []
        for ts_code in tqdm(ts_codes, desc="Fetching by code"):
            df = self._fetch_kline_data_by_code(ts_code, start_date, end_date)
            future = self.io_executor.submit(
                self._save_kline_data_to_sql,
                df
            )   
            pending_futures.append(future)
        
        # 3. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if pending_futures:
            logger.info("Waiting for all fetch and write tasks to complete...")
            success_count = 0
            failed_count = 0
            for future in tqdm(pending_futures, desc="Writing"):
                try:
                    result = future.result()
                    if result:
                        success_count += 1
                    else:
                        failed_count += 1
                except Exception as e:
                    logger.error(f"Task failed with exception: {e}")
                    failed_count += 1
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            total = len(ts_codes)
            logger.info(f"Code mode completed: {success_count} succeeded, {failed_count} failed out of {total} stocks.")
            if failed_count > 0:
                logger.warning(f"âš ï¸  {failed_count} stocks failed to write. Data may be incomplete.")
                logger.warning(f"ğŸ’¡ Tip: Reduce io_executor max_workers to 1-2 to avoid database locks.")
        
        logger.info("Code mode update completed.")
    
    def _update_by_date_mode(self, start_date: str, end_date: str):
        """
        Dateæ¨¡å¼ï¼šä½¿ç”¨ pro.daily API æŒ‰äº¤æ˜“æ—¥è·å–æ•°æ®
        
        æµç¨‹ï¼š
        1. è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰äº¤æ˜“æ—¥
        2. éå†æ¯ä¸ªäº¤æ˜“æ—¥ï¼ˆä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼‰
           2.1. è°ƒç”¨ fetcher.fetch_daily_by_date() è·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®
           2.2. æäº¤åˆ° io_executorï¼Œå¼‚æ­¥æ‰§è¡Œ storage.write_batch() æ‰¹é‡å†™å…¥
        3. ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
        
        æ€§èƒ½ç‰¹ç‚¹ï¼š
        - æŒ‰äº¤æ˜“æ—¥æ‰¹é‡è·å–ï¼Œé€‚åˆå¢é‡æ›´æ–°
        - ä½¿ç”¨ task_executor ä¸²è¡Œè°ƒåº¦ä»»åŠ¡ï¼ˆé¿å…APIå¹¶å‘è¶…é™ï¼‰
        - ä½¿ç”¨ io_executor å¹¶å‘å†™å…¥ï¼ˆæå‡å†™å…¥æ€§èƒ½ï¼‰
        - é€‚åˆè¡¥å……ç‰¹å®šæ—¥æœŸçš„ç¼ºå¤±æ•°æ®
        
        :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        """
        # 1. è·å–æ‰€æœ‰äº¤æ˜“æ—¥
        calendar_df = self.get_calendar()
        if calendar_df is None or calendar_df.empty:
            logger.error("Failed to get trade calendar. Please update calendar first.")
            return
        
        # ç­›é€‰æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥ï¼ˆä½¿ç”¨ DateHelper ç»Ÿä¸€å¤„ç†ä¸º YYYYMMDDï¼‰
        calendar_df_copy = calendar_df.copy()
        if "cal_date" in calendar_df_copy.columns:
            # ç»Ÿä¸€è½¬æ¢ä¸º YYYYMMDD æ ¼å¼è¿›è¡Œæ¯”è¾ƒ
            calendar_df_copy["cal_date"] = calendar_df_copy["cal_date"].astype(str)
            def normalize_date(d):
                try:
                    return DateHelper.normalize(d)
                except:
                    return None
            calendar_df_copy["cal_date"] = calendar_df_copy["cal_date"].apply(normalize_date)
            # ç§»é™¤æ— æ•ˆæ—¥æœŸ
            calendar_df_copy = calendar_df_copy[calendar_df_copy["cal_date"].notna()]
        
        trade_dates = calendar_df_copy[
            (calendar_df_copy['cal_date'] >= start_date) & 
            (calendar_df_copy['cal_date'] <= end_date)
        ]['cal_date'].tolist()
        
        if not trade_dates:
            logger.error(f"No trade dates found in range {start_date}-{end_date}")
            return
        
        trade_dates = sorted(trade_dates)
        logger.info(f"Date mode: Updating Daily Kline for {len(trade_dates)} trade dates...")
        
        # 2. éå†æ¯ä¸ªäº¤æ˜“æ—¥ï¼Œæ‰¹é‡æ›´æ–°
        pending_futures = []
        for trade_date in tqdm(trade_dates, desc="Fetching by date"):
            df = self._fetch_kline_data_by_date(trade_date)
            future = self.io_executor.submit(
                self._save_kline_data_to_sql,
                df
            )   
            pending_futures.append(future)
        
        # 3. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if pending_futures:
            logger.info("Waiting for all fetch and write tasks to complete...")
            success_count = 0
            failed_count = 0
            for future in tqdm(pending_futures, desc="Writing"):
                try:
                    result = future.result()
                    if result:
                        success_count += 1
                    else:
                        failed_count += 1
                except Exception as e:
                    logger.error(f"Task failed with exception: {e}")
                    failed_count += 1
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            total = len(trade_dates)
            logger.info(f"Date mode completed: {success_count} succeeded, {failed_count} failed out of {total} dates.")
            if failed_count > 0:
                logger.warning(f"âš ï¸  {failed_count} dates failed to write. Data may be incomplete.")
                logger.warning(f"ğŸ’¡ Tip: Reduce io_executor max_workers to 1-2 to avoid database locks.")
        logger.info("Date mode update completed.")
    
    
    # ======================== load data =======================  
    def load_kline_data_from_sql(self, ts_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        ä» SQLite æ•°æ®åº“åŠ è½½æ—¥çº¿è¡Œæƒ…æ•°æ®
        """
        return self.daily_storage.load(ts_code, start_date, end_date)